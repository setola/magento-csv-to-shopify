version: "3"

vars:
  CSV_DIR: '{{ .CSV_DIR | default "./data" }}'
  CSV_FILE: 
    sh: find {{ .CSV_DIR }} -maxdepth 1 -type f -iname "export_catalog_product_*.csv" | head -1
  CSV_FILE_TEST: '{{ .CSV_FILE_TEST | default (print .CSV_DIR "/products_test.csv") }}'
  LOGS_DIR: '{{ .LOGS_DIR | default "./logs" }}'

tasks:

  csv:count-rows:
    cmds:
      - docker compose run --rm migration node utils/CSVRowCounter.js {{ .CSV_FILE }}

  csv:search:
    desc: "Search for a term in Magento CSV files and extract complete rows"
    summary: |
      Search for a specific term in Magento product CSV files.
      Properly handles multi-line CSV content (e.g., HTML descriptions).
      
      Usage: go-task csv:search TERM=BIX.A-REM-70S
      Usage: go-task csv:search TERM=DAA.100358
      Usage: go-task csv:search TERM=DAA.100358 CSV_FILE=./export_catalog_product_20251010_200348.csv
      Usage: go-task csv:search TERM=SKU123 > output.csv
    vars:
      TERM: '{{.TERM | default "BIX.A-REM-70S"}}'
    silent: true
    cmds:
      - head -n1 {{ .CSV_FILE }}
      - |
        python3 -c "import csv,sys,io; [csv.writer(sys.stdout).writerow(row) for file in sys.argv[1:] for row in csv.reader(open(file)) if '{{.TERM}}' in ','.join(row)]" {{ .CSV_FILE }} 2>/dev/null || true

  csv:search-sku:
    desc: "Search for exact SKU match in the SKU column only"
    summary: |
      Search for an exact SKU match in the SKU column of Magento CSV files.
      More precise than general search - only matches the SKU field.
      
      Usage: go-task csv:search-sku SKU=BIX.A-REM-70S
      Usage: go-task csv:search-sku SKU=DAA.100358
      Usage: go-task csv:search-sku SKU=SKU123 > output.csv
    vars:
      SKU: '{{.SKU | default "BIX.A-REM-70S"}}'
    silent: true
    cmds:
      - |
        python3 -c "import csv,sys,io; [csv.writer(sys.stdout).writerow(row) for file in sys.argv[1:] for row in csv.reader(open(file)) if len(row) > 0 and row[0] == '{{.SKU}}']" {{ .CSV_FILE }} 2>/dev/null || true

  csv:distinct:
    desc: "Extract distinct values from a CSV column with analysis options"
    summary: |
      Extract distinct values from a specified column in Magento CSV files.
      Supports counting, sorting, and output to files.
      
      Usage Examples:
      go-task csv:distinct COLUMN=product_type
      go-task csv:distinct COLUMN=categories COUNT=true SORT=true
      go-task csv:distinct COLUMN=sku OUTPUT=sku_list.txt
      go-task csv:distinct -- --list-columns
      go-task csv:distinct COLUMN=manufacturer CSV_FILE=./custom.csv
      
      Options:
      COLUMN: Column name to analyze (required unless using --list-columns)
      CSV_FILE: CSV file path (optional, defaults to auto-discovery)
      COUNT: Show count of each value (true/false, default: false)
      SORT: Sort output alphabetically (true/false, default: false) 
      OUTPUT: Save results to file instead of stdout
      
      Special usage:
      go-task csv:distinct -- --list-columns    # List all available columns
      go-task csv:distinct -- --help           # Show detailed help
    vars:
      COLUMN: '{{ .COLUMN | default "" }}'
      CSV_FILE_PARAM: '{{ .CSV_FILE | default "" }}'
      COUNT_FLAG: '{{ if eq .COUNT "true" }}--count{{ end }}'
      SORT_FLAG: '{{ if eq .SORT "true" }}--sort{{ end }}'
      OUTPUT_FLAG: '{{ if .OUTPUT }}--output {{ .OUTPUT }}{{ end }}'
      ARGS: '{{ .CLI_ARGS | default "" }}'
    cmds:
      - |
        if [ "{{ .ARGS }}" != "" ]; then
          # Pass through CLI args directly (for --list-columns, --help, etc.)
          # Use dummy column name and main CSV file for --list-columns
          CSV_ARG="{{ .CSV_FILE }}"
          docker compose run --rm migration node utils/DistinctValueExtractor.js dummy "$CSV_ARG" {{ .ARGS }}
        elif [ "{{ .COLUMN }}" = "" ]; then
          echo "Error: COLUMN parameter is required"
          echo "Usage: go-task csv:distinct COLUMN=column_name [options]"
          echo "Or use: go-task csv:distinct -- --list-columns"
          exit 1
        else
          # Build command with parameters
          CSV_ARG="{{ if .CSV_FILE_PARAM }}{{ .CSV_FILE_PARAM }}{{ else }}{{ .CSV_FILE }}{{ end }}"
          docker compose run --rm migration node utils/DistinctValueExtractor.js "{{ .COLUMN }}" "$CSV_ARG" {{ .COUNT_FLAG }} {{ .SORT_FLAG }} {{ .OUTPUT_FLAG }}
        fi

  csv:extract-by-column:
    desc: "Extract CSV rows where a specified column has content (non-empty)"
    summary: |
      Extract rows from CSV files where a specified column contains content (non-empty values).
      Useful for filtering products based on specific fields like descriptions, categories, etc.
      
      Usage Examples:
      go-task csv:extract-by-column COLUMN=description
      go-task csv:extract-by-column COLUMN=short_description OUTPUT=products_with_descriptions.csv
      go-task csv:extract-by-column COLUMN=categories CSV_FILE=./custom.csv COUNT_ONLY=true
      go-task csv:extract-by-column -- --list-columns
      go-task csv:extract-by-column -- --help
      
      Options:
      COLUMN: Column name to check for content (required unless using --list-columns)
      CSV_FILE: CSV file path (optional, defaults to auto-discovery)
      OUTPUT: Save filtered results to file instead of stdout
      COUNT_ONLY: Only show count of matching rows (true/false, default: false)
      NO_HEADER: Do not include header row in output (true/false, default: false)
      
      Special usage:
      go-task csv:extract-by-column -- --list-columns  # List all available columns
      go-task csv:extract-by-column -- --help         # Show detailed help
    vars:
      COLUMN: '{{ .COLUMN | default "" }}'
      CSV_FILE_PARAM: '{{ .CSV_FILE | default "" }}'
      OUTPUT_FLAG: '{{ if .OUTPUT }}--output {{ .OUTPUT }}{{ end }}'
      COUNT_ONLY_FLAG: '{{ if eq .COUNT_ONLY "true" }}--count-only{{ end }}'
      NO_HEADER_FLAG: '{{ if eq .NO_HEADER "true" }}--no-header{{ end }}'
      ARGS: '{{ .CLI_ARGS | default "" }}'
    cmds:
      - |
        if [ "{{ .ARGS }}" != "" ]; then
          # Pass through CLI args directly (for --list-columns, --help, etc.)
          # Use dummy column name and main CSV file for --list-columns
          CSV_ARG="{{ .CSV_FILE }}"
          docker compose run --rm migration node utils/ColumnContentExtractor.js dummy "$CSV_ARG" {{ .ARGS }}
        elif [ "{{ .COLUMN }}" = "" ]; then
          echo "Error: COLUMN parameter is required"
          echo "Usage: go-task csv:extract-by-column COLUMN=column_name [options]"
          echo "Or use: go-task csv:extract-by-column -- --list-columns"
          exit 1
        else
          # Build command with parameters
          CSV_ARG="{{ if .CSV_FILE_PARAM }}{{ .CSV_FILE_PARAM }}{{ else }}{{ .CSV_FILE }}{{ end }}"
          docker compose run --rm migration node utils/ColumnContentExtractor.js "{{ .COLUMN }}" "$CSV_ARG" {{ .OUTPUT_FLAG }} {{ .COUNT_ONLY_FLAG }} {{ .NO_HEADER_FLAG }}
        fi

  csv:extract-by-value:
    desc: "Extract CSV rows where a column equals a specific value"
    summary: |
      Extract rows from CSV files where a specified column equals an exact value.
      Supports case-insensitive matching and can output to files.
      
      Usage Examples:
      go-task csv:extract-by-value COLUMN=status VALUE=Enabled
      go-task csv:extract-by-value COLUMN=product_type VALUE="simple" OUTPUT=simple_products.csv
      go-task csv:extract-by-value COLUMN=manufacturer VALUE="Apple" CASE_INSENSITIVE=true COUNT_ONLY=true
      go-task csv:extract-by-value -- --list-columns
      
      Options:
      COLUMN: Column name to check (required unless using --list-columns)
      VALUE: Exact value to match (required unless using --list-columns)
      CSV_FILE: CSV file path (optional, defaults to auto-discovery)
      OUTPUT: Save filtered results to file instead of stdout
      COUNT_ONLY: Only show count of matching rows (true/false, default: false)
      NO_HEADER: Do not include header row in output (true/false, default: false)
      CASE_INSENSITIVE: Make matching case-insensitive (true/false, default: false)
    vars:
      COLUMN: '{{ .COLUMN | default "" }}'
      VALUE: '{{ .VALUE | default "" }}'
      CSV_FILE_PARAM: '{{ .CSV_FILE | default "" }}'
      OUTPUT_FLAG: '{{ if .OUTPUT }}--output {{ .OUTPUT }}{{ end }}'
      COUNT_ONLY_FLAG: '{{ if eq .COUNT_ONLY "true" }}--count-only{{ end }}'
      NO_HEADER_FLAG: '{{ if eq .NO_HEADER "true" }}--no-header{{ end }}'
      CASE_INSENSITIVE_FLAG: '{{ if eq .CASE_INSENSITIVE "true" }}--case-insensitive{{ end }}'
      ARGS: '{{ .CLI_ARGS | default "" }}'
    cmds:
      - |
        if [ "{{ .ARGS }}" != "" ]; then
          # Pass through CLI args directly (for --list-columns, --help, etc.)
          CSV_ARG="{{ .CSV_FILE }}"
          docker compose run --rm migration node utils/ColumnContentExtractor.js dummy "$CSV_ARG" {{ .ARGS }}
        elif [ "{{ .COLUMN }}" = "" ] || [ "{{ .VALUE }}" = "" ]; then
          echo "Error: Both COLUMN and VALUE parameters are required"
          echo "Usage: go-task csv:extract-by-value COLUMN=column_name VALUE=target_value [options]"
          echo "Or use: go-task csv:extract-by-value -- --list-columns"
          exit 1
        else
          # Build command with parameters
          CSV_ARG="{{ if .CSV_FILE_PARAM }}{{ .CSV_FILE_PARAM }}{{ else }}{{ .CSV_FILE }}{{ end }}"
          docker compose run --rm migration node utils/ColumnContentExtractor.js "{{ .COLUMN }}" "$CSV_ARG" --value "{{ .VALUE }}" {{ .OUTPUT_FLAG }} {{ .COUNT_ONLY_FLAG }} {{ .NO_HEADER_FLAG }} {{ .CASE_INSENSITIVE_FLAG }}
        fi

  csv:extract-by-contains:
    desc: "Extract CSV rows where a column contains a specific substring"
    summary: |
      Extract rows from CSV files where a specified column contains a substring.
      Supports case-insensitive matching and can output to files.
      
      Usage Examples:
      go-task csv:extract-by-contains COLUMN=name SUBSTRING=iPhone
      go-task csv:extract-by-contains COLUMN=description SUBSTRING="wireless" OUTPUT=wireless_products.csv
      go-task csv:extract-by-contains COLUMN=categories SUBSTRING="electronics" CASE_INSENSITIVE=true COUNT_ONLY=true
      go-task csv:extract-by-contains -- --list-columns
      
      Options:
      COLUMN: Column name to check (required unless using --list-columns)
      SUBSTRING: Substring to search for (required unless using --list-columns)
      CSV_FILE: CSV file path (optional, defaults to auto-discovery)
      OUTPUT: Save filtered results to file instead of stdout
      COUNT_ONLY: Only show count of matching rows (true/false, default: false)
      NO_HEADER: Do not include header row in output (true/false, default: false)
      CASE_INSENSITIVE: Make matching case-insensitive (true/false, default: false)
    vars:
      COLUMN: '{{ .COLUMN | default "" }}'
      SUBSTRING: '{{ .SUBSTRING | default "" }}'
      CSV_FILE_PARAM: '{{ .CSV_FILE | default "" }}'
      OUTPUT_FLAG: '{{ if .OUTPUT }}--output {{ .OUTPUT }}{{ end }}'
      COUNT_ONLY_FLAG: '{{ if eq .COUNT_ONLY "true" }}--count-only{{ end }}'
      NO_HEADER_FLAG: '{{ if eq .NO_HEADER "true" }}--no-header{{ end }}'
      CASE_INSENSITIVE_FLAG: '{{ if eq .CASE_INSENSITIVE "true" }}--case-insensitive{{ end }}'
      ARGS: '{{ .CLI_ARGS | default "" }}'
    cmds:
      - |
        if [ "{{ .ARGS }}" != "" ]; then
          # Pass through CLI args directly (for --list-columns, --help, etc.)
          CSV_ARG="{{ .CSV_FILE }}"
          docker compose run --rm migration node utils/ColumnContentExtractor.js dummy "$CSV_ARG" {{ .ARGS }}
        elif [ "{{ .COLUMN }}" = "" ] || [ "{{ .SUBSTRING }}" = "" ]; then
          echo "Error: Both COLUMN and SUBSTRING parameters are required"
          echo "Usage: go-task csv:extract-by-contains COLUMN=column_name SUBSTRING=search_text [options]"
          echo "Or use: go-task csv:extract-by-contains -- --list-columns"
          exit 1
        else
          # Build command with parameters
          CSV_ARG="{{ if .CSV_FILE_PARAM }}{{ .CSV_FILE_PARAM }}{{ else }}{{ .CSV_FILE }}{{ end }}"
          docker compose run --rm migration node utils/ColumnContentExtractor.js "{{ .COLUMN }}" "$CSV_ARG" --contains "{{ .SUBSTRING }}" {{ .OUTPUT_FLAG }} {{ .COUNT_ONLY_FLAG }} {{ .NO_HEADER_FLAG }} {{ .CASE_INSENSITIVE_FLAG }}
        fi

  csv:extract-test-products:
    vars:
      SKUS: >
        BIX.A-REM-70S
        DAA.100358
        GLK.33781
        WLK.WALGWP-SLCR2-BT
    cmds:
      - head -n1 {{ .CSV_FILE }} > {{ .CSV_FILE_TEST }}
      - for: { var: SKUS }
        cmd: python3 -c "import csv,sys,io; [csv.writer(sys.stdout).writerow(row) for file in sys.argv[1:] for row in csv.reader(open(file)) if len(row) > 0 and row[0] == '{{ .ITEM }}']" {{ .CSV_FILE }} 2>/dev/null 1>> {{ .CSV_FILE_TEST }}

  migration:migrate:
    cmds:
      - docker compose up
  
  migration:customers:
    desc: "Run customer migration using Docker (without compose)"
    summary: |
      Run customer migration directly with Docker without using docker compose.
      Uses the NODE_IMAGE environment variable or defaults to node:alpine.
      
      Usage:
      go-task migration:customers
      go-task migration:customers NODE_IMAGE=node:18-alpine
      go-task migration:customers START_ROW=100 BATCH_SIZE=50
      
      Environment variables:
      NODE_IMAGE: Docker image to use (default: node:alpine)
      START_ROW: Starting row for batch processing
      BATCH_SIZE: Number of customers per batch
      All other environment variables from .env file are passed through
    vars:
      NODE_IMAGE: '{{ .NODE_IMAGE | default "node:alpine" }}'
      DOCKER_LOGS_DIR: '{{ .DOCKER_LOGS_DIR | default "/app/logs" }}'
    cmds:
      - |
        # Create logs directory if it doesn't exist
        mkdir -p {{ .LOGS_DIR }}
        
        # Run customer migration in Docker
        docker run --rm -it \
          --name magento-shopify-customer-migration \
          --workdir /app \
          --volume "$(pwd):/app" \
          --env-file .env \
          {{ if .START_ROW }}--env "START_ROW={{ .START_ROW }}" {{ end }}\
          {{ if .BATCH_SIZE }}--env "BATCH_SIZE={{ .BATCH_SIZE }}" {{ end }}\
          {{ if .MAX_CONCURRENT }}--env "MAX_CONCURRENT={{ .MAX_CONCURRENT }}" {{ end }}\
          {{ if .DELAY_MS }}--env "DELAY_MS={{ .DELAY_MS }}" {{ end }}\
          {{ if .CUSTOMERS_CSV_PATH }}--env "CUSTOMERS_CSV_PATH={{ .CUSTOMERS_CSV_PATH }}" {{ end }}\
          {{ .NODE_IMAGE }} \
          npm run migrate-customers
  
  migration:products:
    desc: "Run product migration using Docker (without compose)"
    summary: |
      Run product migration directly with Docker without using docker compose.
      Uses the NODE_IMAGE environment variable or defaults to node:alpine.
      
      Usage:
      go-task migration:products
      go-task migration:products NODE_IMAGE=node:18-alpine
      go-task migration:products START_ROW=100 BATCH_SIZE=500
      
      Environment variables:
      NODE_IMAGE: Docker image to use (default: node:alpine)
      START_ROW: Starting row for batch processing
      BATCH_SIZE: Number of products per batch
      All other environment variables from .env file are passed through
    vars:
      NODE_IMAGE: '{{ .NODE_IMAGE | default "node:alpine" }}'
      DOCKER_LOGS_DIR: '{{ .DOCKER_LOGS_DIR | default "/app/logs" }}'
    cmds:
      - |
        # Create logs directory if it doesn't exist
        mkdir -p {{ .LOGS_DIR }}
        
        # Run product migration in Docker
        docker run --rm -it \
          --name magento-shopify-product-migration \
          --workdir /app \
          --volume "$(pwd):/app" \
          --env-file .env \
          {{ if .START_ROW }}--env "START_ROW={{ .START_ROW }}" {{ end }}\
          {{ if .BATCH_SIZE }}--env "BATCH_SIZE={{ .BATCH_SIZE }}" {{ end }}\
          {{ if .MAX_CONCURRENT }}--env "MAX_CONCURRENT={{ .MAX_CONCURRENT }}" {{ end }}\
          {{ if .DELAY_MS }}--env "DELAY_MS={{ .DELAY_MS }}" {{ end }}\
          {{ if .CSV_PATH }}--env "CSV_PATH={{ .CSV_PATH }}" {{ end }}\
          {{ .NODE_IMAGE }} \
          npm run migrate-products
  
  migration:progress:
    cmds:
      - tail -fn1 {{ .LOGS_DIR }}/*.log | grep "Progress:"
